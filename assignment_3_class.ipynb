{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ae2732",
   "metadata": {},
   "source": [
    "## Experiment 2 ##\n",
    "### predicting class of new articles with second model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5682f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Gensim for corpus and model\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Import NLTK for stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477ddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the BBC news dataset\n",
    "data_folder=\"C:/users/funny/bbc\"\n",
    "\n",
    "folders=[\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "for i in folders:\n",
    "    files=os.listdir(data_folder+'/'+i)\n",
    "    for text_file in files:\n",
    "        file_path=data_folder + '/'+i+'/'+text_file\n",
    "        with open(file_path,'rb') as f:\n",
    "            data=f.read()\n",
    "        x.append(data)\n",
    "        y.append(i)\n",
    "        \n",
    "data={'text':x,'type':y}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e811db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gensim's simple preprocess to tokenize words from sentences\n",
    "def tokenize(sentences, deacc=True):\n",
    "    for sentence in sentences:\n",
    "        yield(simple_preprocess(str(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650b7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stopwords from NLTK's model of english stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Def function for removing stopwords in each tokenized text body\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec9a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data and tokenize body texts\n",
    "data = df['text'].values.tolist()\n",
    "data_words = list(tokenize(data))\n",
    "\n",
    "# Filter stopwords from tokenized texts\n",
    "data_no_stopwords = remove_stopwords(data_words)\n",
    "\n",
    "# Build dictionary from POS tagged data\n",
    "dictionary = corpora.Dictionary(data_no_stopwords)\n",
    "\n",
    "# Build corpus using lemmatized texts\n",
    "texts = data_no_stopwords\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Gather labels as a list for passing through train-test split\n",
    "labels = df['type'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf42bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric values for labels\n",
    "num_lab = labels[:]\n",
    "num_lab = [0 if x == \"business\" else x for x in num_lab]\n",
    "num_lab = [1 if x == \"entertainment\" else x for x in num_lab]\n",
    "num_lab = [2 if x == \"politics\" else x for x in num_lab]\n",
    "num_lab = [3 if x == \"sport\" else x for x in num_lab]\n",
    "num_lab = [4 if x == \"tech\" else x for x in num_lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719f3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making eta hyperparameter\n",
    "# returns an topics*terms matrix \n",
    "def get_eta(topics, terms, prior):\n",
    "    matrix = np.zeros((5,len(terms)), dtype=int)\n",
    "    matrix = matrix.tolist()\n",
    "    \n",
    "    for n in range(len(prior)):\n",
    "        for m in range(len(prior[n])):\n",
    "            matrix[topics[n]][prior[n][m][0]] += prior[n][m][1]\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15ae96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = get_eta(num_lab, dictionary, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd609a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662ca603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using train-test split\n",
    "LDA_model = gensim.models.ldamodel.LdaModel(corpus=X_train,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=5,\n",
    "                                            random_state=42,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha=\"auto\",\n",
    "                                            eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd1ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting highest predicted cluster of text\n",
    "def predict_topic(array):\n",
    "    pred_topic = array[0][0]\n",
    "    best_similarity = array[0][1]\n",
    "    \n",
    "    for n in range(len(array)):\n",
    "        if array[n][1] > best_similarity:\n",
    "            pred_topic = array[n][0]\n",
    "            best_similarity = array[n][1]\n",
    "    return pred_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff404d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading newly scraped articles from the BBC\n",
    "data_folder=\"C:/users/funny/bbc_scraped\"\n",
    "\n",
    "folders=[\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "for i in folders:\n",
    "    files=os.listdir(data_folder+'/'+i)\n",
    "    for text_file in files:\n",
    "        file_path=data_folder + '/'+i+'/'+text_file\n",
    "        with open(file_path,'rb') as f:\n",
    "            data=f.read()\n",
    "        x.append(data)\n",
    "        y.append(i)\n",
    "        \n",
    "data={'text':x,'type':y}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8faa2b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'EU signs US gas deal to curb reliance on Rus...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'US jobless claims at lowest level since 1969...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Calls for P&amp;O Ferries boss Peter Hebblethwai...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Watch: Beyonc\\xc3\\xa9's Oscar performance in...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Charity boss on her thoughts for Jada Pinket...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'Colin Paterson: I\\'m amazed Smith came to th...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'Ukraine: No Russia regime change plans, says...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'Ukraine not alone in fight against Russia, s...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'South Sudan forces withdraw from VP Machar\\'...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'Joe Root wants to stay as England captain de...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'Women\\'s World Cup: England had \\'belief\\' i...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'Ashleigh Barty retires: Her time at the top ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'Russia hacked Ukrainian satellite communicat...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b'Europe agrees new law to curb Big Tech domin...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'Mobile loophole for gaming drivers is closed...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text           type\n",
       "0   b'EU signs US gas deal to curb reliance on Rus...       business\n",
       "1   b'US jobless claims at lowest level since 1969...       business\n",
       "2   b'Calls for P&O Ferries boss Peter Hebblethwai...       business\n",
       "3   b\"Watch: Beyonc\\xc3\\xa9's Oscar performance in...  entertainment\n",
       "4   b'Charity boss on her thoughts for Jada Pinket...  entertainment\n",
       "5   b'Colin Paterson: I\\'m amazed Smith came to th...  entertainment\n",
       "6   b'Ukraine: No Russia regime change plans, says...       politics\n",
       "7   b'Ukraine not alone in fight against Russia, s...       politics\n",
       "8   b'South Sudan forces withdraw from VP Machar\\'...       politics\n",
       "9   b'Joe Root wants to stay as England captain de...          sport\n",
       "10  b'Women\\'s World Cup: England had \\'belief\\' i...          sport\n",
       "11  b'Ashleigh Barty retires: Her time at the top ...          sport\n",
       "12  b'Russia hacked Ukrainian satellite communicat...           tech\n",
       "13  b'Europe agrees new law to curb Big Tech domin...           tech\n",
       "14  b'Mobile loophole for gaming drivers is closed...           tech"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c00ce43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data and tokenize body texts\n",
    "data = df['text'].values.tolist()\n",
    "data_words = list(tokenize(data))\n",
    "\n",
    "# Filter stopwords from tokenized texts\n",
    "data_no_stopwords = remove_stopwords(data_words)\n",
    "\n",
    "# Build dictionary from POS tagged data\n",
    "#dictionary = corpora.Dictionary(data_no_stopwords)\n",
    "\n",
    "# Build corpus using lemmatized texts\n",
    "texts = data_no_stopwords\n",
    "new_corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Gather labels as a list for passing through train-test split\n",
    "labels = df['type'].values.tolist()\n",
    "\n",
    "# Get numeric values for labels\n",
    "num_lab = labels[:]\n",
    "num_lab = [0 if x == \"business\" else x for x in num_lab]\n",
    "num_lab = [1 if x == \"entertainment\" else x for x in num_lab]\n",
    "num_lab = [2 if x == \"politics\" else x for x in num_lab]\n",
    "num_lab = [3 if x == \"sport\" else x for x in num_lab]\n",
    "num_lab = [4 if x == \"tech\" else x for x in num_lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2174ab0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ecd74c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.412531), (3, 0.045850545), (4, 0.541382)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.get_document_topics(new_corpus[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b4d739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the classes of the new articles\n",
    "check_class = []\n",
    "\n",
    "for n in range(len(new_corpus)):\n",
    "    a = predict_topic(LDA_model.get_document_topics(new_corpus[n]))\n",
    "    check_class.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b581ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted incorrectly.\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "Article predicted incorrectly.\n",
      "Article predicted correctly!\n",
      "Article predicted correctly!\n",
      "\n",
      "Number of new articles predicted correctly: 13\n",
      "\n",
      "Number of new articles predicted incorrectly: 2\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for n in range(len(check_class)):\n",
    "    \n",
    "    if check_class[n] == num_lab[n]:\n",
    "        print(\"Article predicted correctly!\")\n",
    "        correct += 1\n",
    "    elif check_class[n] != num_lab[n]:\n",
    "        print(\"Article predicted incorrectly.\")\n",
    "        incorrect += 1\n",
    "print(\"\\nNumber of new articles predicted correctly: {}\".format(correct))\n",
    "print(\"\\nNumber of new articles predicted incorrectly: {}\".format(incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b8026",
   "metadata": {},
   "source": [
    "Even though the new articles are over a decade newer, the model was still able to predict with a decent success rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
