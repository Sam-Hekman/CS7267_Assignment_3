{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940341d2",
   "metadata": {},
   "source": [
    "## Experiment 1 ##\n",
    "### Evaluate using eta ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5682f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Gensim for corpus and model\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Import NLTK for stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477ddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the BBC news dataset\n",
    "data_folder=\".../bbc\"\n",
    "\n",
    "folders=[\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "for i in folders:\n",
    "    files=os.listdir(data_folder+'/'+i)\n",
    "    for text_file in files:\n",
    "        file_path=data_folder + '/'+i+'/'+text_file\n",
    "        with open(file_path,'rb') as f:\n",
    "            data=f.read()\n",
    "        x.append(data)\n",
    "        y.append(i)\n",
    "        \n",
    "data={'text':x,'type':y}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e811db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gensim's simple preprocess to tokenize words from sentences\n",
    "def tokenize(sentences, deacc=True):\n",
    "    for sentence in sentences:\n",
    "        yield(simple_preprocess(str(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650b7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stopwords from NLTK's model of english stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Def function for removing stopwords in each tokenized text body\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec9a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data and tokenize body texts\n",
    "data = df['text'].values.tolist()\n",
    "data_words = list(tokenize(data))\n",
    "\n",
    "# Filter stopwords from tokenized texts\n",
    "data_no_stopwords = remove_stopwords(data_words)\n",
    "\n",
    "# Build dictionary from POS tagged data\n",
    "dictionary = corpora.Dictionary(data_no_stopwords)\n",
    "\n",
    "# Build corpus using lemmatized texts\n",
    "texts = data_no_stopwords\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Gather labels as a list for passing through train-test split\n",
    "labels = df['type'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753a127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric values for labels\n",
    "num_lab = labels[:]\n",
    "num_lab = [0 if x == \"business\" else x for x in num_lab]\n",
    "num_lab = [1 if x == \"entertainment\" else x for x in num_lab]\n",
    "num_lab = [2 if x == \"politics\" else x for x in num_lab]\n",
    "num_lab = [3 if x == \"sport\" else x for x in num_lab]\n",
    "num_lab = [4 if x == \"tech\" else x for x in num_lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4496405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making eta hyperparameter\n",
    "# returns an topics*terms matrix \n",
    "def get_eta(topics, terms, prior):\n",
    "    matrix = np.zeros((5,len(terms)), dtype=int)\n",
    "    matrix = matrix.tolist()\n",
    "    \n",
    "    for n in range(len(prior)):\n",
    "        for m in range(len(prior[n])):\n",
    "            matrix[topics[n]][prior[n][m][0]] += prior[n][m][1]\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865b1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = get_eta(num_lab, dictionary, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd609a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662ca603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using train-test split\n",
    "LDA_model = gensim.models.ldamodel.LdaModel(corpus=X_train,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=5,\n",
    "                                            random_state=42,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha=\"auto\",\n",
    "                                            eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81e25b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"said\" + 0.008*\"us\" + 0.008*\"bn\" + 0.007*\"year\" + 0.005*\"nthe\" + 0.005*\"mr\" + 0.005*\"xc\" + 0.005*\"xa\" + 0.005*\"would\" + 0.005*\"company\"'),\n",
       " (1,\n",
       "  '0.011*\"film\" + 0.011*\"said\" + 0.009*\"best\" + 0.006*\"year\" + 0.006*\"music\" + 0.005*\"also\" + 0.005*\"one\" + 0.005*\"us\" + 0.005*\"show\" + 0.005*\"nthe\"'),\n",
       " (2,\n",
       "  '0.021*\"said\" + 0.014*\"mr\" + 0.010*\"would\" + 0.007*\"government\" + 0.007*\"labour\" + 0.006*\"people\" + 0.006*\"election\" + 0.006*\"party\" + 0.005*\"blair\" + 0.004*\"also\"'),\n",
       " (3,\n",
       "  '0.010*\"said\" + 0.005*\"first\" + 0.005*\"game\" + 0.005*\"year\" + 0.005*\"england\" + 0.005*\"win\" + 0.004*\"time\" + 0.004*\"two\" + 0.004*\"one\" + 0.004*\"last\"'),\n",
       " (4,\n",
       "  '0.013*\"said\" + 0.008*\"people\" + 0.005*\"also\" + 0.004*\"one\" + 0.004*\"technology\" + 0.004*\"new\" + 0.004*\"mr\" + 0.004*\"mobile\" + 0.004*\"would\" + 0.004*\"nthe\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ef6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding each possible unique pair of testing texts or labels\n",
    "def nCk_pairs(array):\n",
    "    paired = []\n",
    "    \n",
    "    for n in range(len(array)):\n",
    "        for k in range(len(array[n:])):\n",
    "            if k != 0:\n",
    "                paired.append([array[n],array[n+k]])\n",
    "    return paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e501fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2d arrays for pairs of x_test and y_test\n",
    "testing_labels = nCk_pairs(y_test)\n",
    "testing_texts = nCk_pairs(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83782a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98790\n",
      "98790\n"
     ]
    }
   ],
   "source": [
    "# Check that both are the same size array (445 choose 2)\n",
    "print(len(testing_texts))\n",
    "print(len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd1ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting highest predicted cluster of text\n",
    "def predict_topic(array):\n",
    "    pred_topic = array[0][0]\n",
    "    best_similarity = array[0][1]\n",
    "    \n",
    "    for n in range(len(array)):\n",
    "        if array[n][1] > best_similarity:\n",
    "            pred_topic = array[n][0]\n",
    "            best_similarity = array[n][1]\n",
    "    return pred_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643d3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paired list of predicted clusters, this cell takes a couple of minutes to get all predictions\n",
    "testing_results = []\n",
    "\n",
    "for text in range(len(testing_texts)):\n",
    "    a = predict_topic(LDA_model.get_document_topics(testing_texts[text][0]))\n",
    "    b = predict_topic(LDA_model.get_document_topics(testing_texts[text][1]))\n",
    "    testing_results.append([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf33aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ground truth and prediction \n",
    "def get_results(texts, labels):\n",
    "    # same GT, same pred\n",
    "    GS_PS = 0\n",
    "    # same GT, different pred\n",
    "    GS_PD = 0\n",
    "    # differnt GT, same pred\n",
    "    GD_PS = 0\n",
    "    # different GT, different pred\n",
    "    GD_PD = 0\n",
    "    \n",
    "    for n in range(len(texts)):\n",
    "        if texts[n][0] == texts[n][1] and labels[n][0] == labels[n][1]:\n",
    "            GS_PS += 1\n",
    "        elif texts[n][0] != texts[n][1] and labels[n][0] == labels[n][1]:\n",
    "            GS_PD += 1\n",
    "        elif texts[n][0] == texts[n][1] and labels[n][0] != labels[n][1]:\n",
    "            GD_PS += 1\n",
    "        elif texts[n][0] != texts[n][1] and labels[n][0] != labels[n][1]:\n",
    "            GD_PD += 1\n",
    "   \n",
    "    precision = GS_PS/(GS_PS+GD_PS)\n",
    "    recall = GS_PS/(GS_PS+GS_PD)\n",
    "    F1 = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(\"--- Results -----------------\")\n",
    "    print(\"GT same, PRED same: {}\".format(GS_PS))\n",
    "    print(\"GT same, PRED different: {}\".format(GS_PD))\n",
    "    print(\"GT different, PRED same: {}\".format(GD_PS))\n",
    "    print(\"GT different, PRED different: {}\".format(GD_PD))\n",
    "    print(\"\\nPrecision: {}\".format(precision))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F1 score: {}\".format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8745172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results -----------------\n",
      "GT same, PRED same: 19720\n",
      "GT same, PRED different: 552\n",
      "GT different, PRED same: 493\n",
      "GT different, PRED different: 78025\n",
      "\n",
      "Precision: 0.975609756097561\n",
      "Recall: 0.9727703235990529\n",
      "F1 score: 0.9741879708534025\n"
     ]
    }
   ],
   "source": [
    "get_results(testing_results, testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a565a",
   "metadata": {},
   "source": [
    "The prediction is a bit better than the prediction result in the experiment 1 description."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
